{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "# Webscrapping Houston Apartment \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "# Building a function to eliminate Nonetype attributes.\n",
    "\n",
    "def pass_amen(io):\n",
    "    \n",
    "    if io == None:\n",
    "        out = \"Null\"\n",
    "    else:\n",
    "        out = io.get_text()\n",
    "    return out\n",
    "\n",
    "\n",
    "house_book = list()\n",
    "\n",
    "for pages in  range(0,28):\n",
    "    \n",
    "    url = f\"https://www.apartments.com/houston-tx/{pages}\"\n",
    "    #print(url)\n",
    "    \n",
    "    # User agent for parsering\n",
    "    \n",
    "    headers ={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
    "    \n",
    "    # Using the request.get with \"header = headers indicating the users agent.\"\n",
    "    \n",
    "    page = requests.get(url,headers = headers)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    \n",
    "    pages = soup.find_all(\"li\",class_=\"mortar-wrapper\")\n",
    "    \n",
    "    #print(pages)\n",
    "    \n",
    "    for place in pages:\n",
    "        \n",
    "        # Property title \n",
    "        title = place.find('a').get_text().split(\",\")\n",
    "        address = title[0].splitlines()\n",
    "        house_clean = address[1]\n",
    "        #print(house_clean)\n",
    "        \n",
    "        \n",
    "        # Address\n",
    "        title = place.find('a').get_text().split(\",\")\n",
    "        address = title[0].splitlines()\n",
    "        address_clean = address[2]\n",
    "        #print(address_clean)\n",
    "        \n",
    "        # City\n",
    "        title = place.find('a').get_text().split(\",\")\n",
    "        city = title[1]\n",
    "        #print(city)\n",
    "        \n",
    "        # Zipcode\n",
    "        title = place.find('a').get_text().split(\",\")\n",
    "        zipcode = title[2]\n",
    "        clean_zipcode = zipcode.replace('\\n','')\n",
    "        #print(clean_zipcode)\n",
    "        \n",
    "        # Bed_Rooms\n",
    "        info1 = place.find_all(\"div\",class_=\"property-info\")\n",
    "        for beds in info1:\n",
    "            bed_info = beds.find(\"p\",class_=\"property-beds\").get_text()\n",
    "            #print(bed_info)\n",
    "\n",
    "        # Apartment price\n",
    "        price = place.find(\"p\",class_=\"property-pricing\").get_text()\n",
    "        #print(price)\n",
    "        \n",
    "        # new amenities\n",
    "        amenities = place.find(\"p\",class_=\"property-amenities\")\n",
    "        new_amenities = pass_amen(amenities)\n",
    "   \n",
    "        house_book.append([house_clean,address_clean,city,clean_zipcode,bed_info,price,new_amenities])\n",
    "\n",
    "    \n",
    "    \n",
    "# parsing the appended list to the pandas dataframe and saving it as an excel file.\n",
    "df = pd.DataFrame(house_book,columns =['title','Address','City','Zipcode','Bed_Rooms','price','amenities'])\n",
    "df.to_excel('houston_updated.xlsx')\n",
    "\n",
    "print(\"completed\")\n",
    "    \n",
    "\n",
    "## Source: apartment.com\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
